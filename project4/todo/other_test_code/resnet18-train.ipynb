{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":78042,"databundleVersionId":8558952,"sourceType":"competition"}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n        # print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-11T17:13:22.220666Z","iopub.execute_input":"2024-06-11T17:13:22.221024Z","iopub.status.idle":"2024-06-11T17:13:23.340247Z","shell.execute_reply.started":"2024-06-11T17:13:22.220995Z","shell.execute_reply":"2024-06-11T17:13:23.339251Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, TensorDataset, ConcatDataset\nfrom sklearn.model_selection import train_test_split\n\n# GPU device\ndevice = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-11T17:13:23.341977Z","iopub.execute_input":"2024-06-11T17:13:23.342727Z","iopub.status.idle":"2024-06-11T17:13:29.116742Z","shell.execute_reply.started":"2024-06-11T17:13:23.342698Z","shell.execute_reply":"2024-06-11T17:13:29.115698Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# get file name\ntestFileName = list()\ntrainFileNameClass0 = list()\ntrainFileNameClass1 = list()\nos.chdir('/kaggle/input/nycu-ml-pattern-recognition-hw-4/released/test')\ntestFileName = os.listdir()\nos.chdir('../train/class_0')\ntrainFileNameClass0 = os.listdir()\nos.chdir('../class_1')\ntrainFileNameClass1 = os.listdir()\nos.chdir('../../')\n# test file name\ntestFileName[0], trainFileNameClass0[0], trainFileNameClass1[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-11T17:13:29.119329Z","iopub.execute_input":"2024-06-11T17:13:29.120112Z","iopub.status.idle":"2024-06-11T17:13:29.139463Z","shell.execute_reply.started":"2024-06-11T17:13:29.120075Z","shell.execute_reply":"2024-06-11T17:13:29.138533Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"('7c08c8c0-0064-40c3-a7cd-dda2b4043347.pkl',\n '32767294-e76e-485e-91a0-c2a123498e01.pkl',\n '3cc6a03d-7585-48f4-82cc-89448620b059.pkl')"},"metadata":{}}]},{"cell_type":"code","source":"def readData(filepath, filenamelist):\n    FileExtensionRemove = []\n    with open(filepath+filenamelist[0], 'rb') as f:\n        data = np.array([pickle.load(f)])\n    FileExtensionRemove.append(filenamelist[0][:-4])\n    for filename in filenamelist[1:]:\n        with open(filepath+filename, 'rb') as f:\n            data = np.concatenate((data, np.array([pickle.load(f)])), axis=0)\n        FileExtensionRemove.append(filename[:-4])\n    return data, FileExtensionRemove\n\ndef DataPreprocess(trainX0, trainX1=None):\n    # combine train data\n    if trainX1 is None:\n        trainX = trainX0\n    else:\n        trainX = np.concatenate((trainX0, trainX1))\n    # Transform to 0 ~ 1\n    trainX = trainX.astype('float32')\n    trainX /= 255\n    # To pytorch\n    trainX = torch.from_numpy(trainX)\n    if trainX1 is None:\n        trainY = None\n    else:\n        trainY = torch.concatenate((torch.zeros((trainX0.shape[0],1)), \n                                    torch.ones((trainX1.shape[0],1))))\n    return trainX, trainY","metadata":{"execution":{"iopub.status.busy":"2024-06-11T17:13:29.142161Z","iopub.execute_input":"2024-06-11T17:13:29.142821Z","iopub.status.idle":"2024-06-11T17:13:29.153630Z","shell.execute_reply.started":"2024-06-11T17:13:29.142788Z","shell.execute_reply":"2024-06-11T17:13:29.152684Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"DataSizeBatch = 25\ntrain_loader = []\nval_loader = []\nfor i in range(int(len(trainFileNameClass0)/DataSizeBatch)):\n    print(\"read batch\", i)\n    startIndex = i * DataSizeBatch\n    trainX0, _ = readData('train/class_0/', trainFileNameClass0[startIndex:startIndex + DataSizeBatch])\n    trainX1, _ = readData('train/class_1/', trainFileNameClass1[startIndex:startIndex + DataSizeBatch])\n    \n    trainX, trainY = DataPreprocess(trainX0, trainX1)\n    # Split data into train and validation sets\n    trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size=0.2)\n    \n    # Create DataLoader for batching\n    train_dataset = TensorDataset(trainX, trainY)\n    val_dataset = TensorDataset(valX, valY)\n\n    train_loader.append(DataLoader(train_dataset, batch_size=4, shuffle=True))\n    val_loader.append(DataLoader(val_dataset, batch_size=4, shuffle=False))\n    \n\n# Try to merge dataloader\n#trainLoader = DataLoader(ConcatDataset([dsa, dsb]))\n#valLoader = DataLoader(ConcatDataset([dsa, dsb]))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-11T17:13:29.154854Z","iopub.execute_input":"2024-06-11T17:13:29.155453Z","iopub.status.idle":"2024-06-11T17:14:44.015487Z","shell.execute_reply.started":"2024-06-11T17:13:29.155422Z","shell.execute_reply":"2024-06-11T17:14:44.014452Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"read batch 0\nread batch 1\nread batch 2\nread batch 3\nread batch 4\nread batch 5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Feature extraction model using ResNet18\nclass FeatureExtractor(nn.Module):\n    def __init__(self):\n        super(FeatureExtractor, self).__init__()\n        base_model = models.resnet18(weights='IMAGENET1K_V1')\n        self.feature_extractor = nn.Sequential(\n            *list(base_model.children())[:-1],\n            nn.Flatten()\n        )\n    \n    def forward(self, x):\n        x = self.feature_extractor(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-11T17:14:44.016950Z","iopub.execute_input":"2024-06-11T17:14:44.017590Z","iopub.status.idle":"2024-06-11T17:14:44.023222Z","shell.execute_reply.started":"2024-06-11T17:14:44.017563Z","shell.execute_reply":"2024-06-11T17:14:44.022380Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"FEATURE_DIM = 512\n# MIL model\nclass MILModel(nn.Module):\n    def __init__(self):\n        super(MILModel, self).__init__()\n        self.feature_extractor = FeatureExtractor()\n        self.classifier = nn.Linear(FEATURE_DIM, 1)\n    \n    def forward(self, x):\n        batch_size = x.size(0)\n        num_tiles = x.size(1)\n        x = x.view(-1, 3, 128, 128)\n        features = self.feature_extractor(x)\n        features = features.view(batch_size, num_tiles, -1)\n        aggregated_features, _ = torch.max(features, dim=1)\n        logits = self.classifier(aggregated_features)\n        output = torch.sigmoid(logits)\n        return output\n\n    def predict(self, x):\n        with torch.no_grad():\n            ypred_prob = self(x)\n            ypred = ypred_prob.clone().detach()\n            ypred[ypred < 0.5] = 0\n            ypred[ypred >= 0.5] = 1\n            return ypred_prob, ypred","metadata":{"execution":{"iopub.status.busy":"2024-06-11T17:14:44.024672Z","iopub.execute_input":"2024-06-11T17:14:44.025464Z","iopub.status.idle":"2024-06-11T17:14:44.040902Z","shell.execute_reply.started":"2024-06-11T17:14:44.025431Z","shell.execute_reply":"2024-06-11T17:14:44.040028Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Set random seed for reproducibility\ntorch.manual_seed(0)\n\n# Initialize the model\nmodel = MILModel().to(device)\nprint(model)\n\n# Define loss and optimizer\ncriterion = nn.BCELoss()\n# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2024-06-11T17:14:44.042066Z","iopub.execute_input":"2024-06-11T17:14:44.042373Z","iopub.status.idle":"2024-06-11T17:14:44.773894Z","shell.execute_reply.started":"2024-06-11T17:14:44.042344Z","shell.execute_reply":"2024-06-11T17:14:44.772952Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 181MB/s]\n","output_type":"stream"},{"name":"stdout","text":"MILModel(\n  (feature_extractor): FeatureExtractor(\n    (feature_extractor): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (4): Sequential(\n        (0): BasicBlock(\n          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (1): BasicBlock(\n          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): Sequential(\n        (0): BasicBlock(\n          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): BasicBlock(\n          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (6): Sequential(\n        (0): BasicBlock(\n          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (downsample): Sequential(\n            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): BasicBlock(\n          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (7): Sequential(\n        (0): BasicBlock(\n          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): BasicBlock(\n          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n      (9): Flatten(start_dim=1, end_dim=-1)\n    )\n  )\n  (classifier): Linear(in_features=512, out_features=1, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"\nnum_epochs = 5\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for tl in train_loader:\n        for i, (inputs, targets) in enumerate(tl):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            running_loss += loss.item()\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n    avg_train_loss = running_loss / (len(tl) * len(train_loader))\n    \n    model.eval()\n    val_loss = 0.0\n    for vl in val_loader:\n        with torch.no_grad():\n            for inputs, targets in vl:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                val_loss += loss.item()\n    avg_val_loss = val_loss / (len(vl)* len(val_loader))\n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\nprint('Training finished.')","metadata":{"execution":{"iopub.status.busy":"2024-06-11T17:14:44.774941Z","iopub.execute_input":"2024-06-11T17:14:44.775210Z","iopub.status.idle":"2024-06-11T17:18:10.458026Z","shell.execute_reply.started":"2024-06-11T17:14:44.775176Z","shell.execute_reply":"2024-06-11T17:18:10.457082Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch [1/5], Train Loss: 0.7909, Val Loss: 0.5913\nEpoch [2/5], Train Loss: 0.0620, Val Loss: 0.6652\nEpoch [3/5], Train Loss: 0.0048, Val Loss: 0.6593\nEpoch [4/5], Train Loss: 0.0029, Val Loss: 0.6660\nEpoch [5/5], Train Loss: 0.0021, Val Loss: 0.6709\nTraining finished.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save model weight\ntorch.save(model.state_dict(), \"/kaggle/working/weight-resnet18.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-06-11T17:18:10.460563Z","iopub.execute_input":"2024-06-11T17:18:10.460835Z","iopub.status.idle":"2024-06-11T17:18:10.539394Z","shell.execute_reply.started":"2024-06-11T17:18:10.460812Z","shell.execute_reply":"2024-06-11T17:18:10.538276Z"},"trusted":true},"execution_count":10,"outputs":[]}]}